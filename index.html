<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Drone SocketIo</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css" integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">
</head>
<body>
    <div class="pr-4 text-center">  
        <h1 class="jumbotron text-center">Controla tu drone desde aqui</h1>
        <div class="row d-flex justify-content-center">
            <button class="btn btn-success mt-4 mr-4" id="takeoff">TAKEOFF</button>
            <button class="btn btn-danger mt-4 mr-4" id="stop">STOP</button>
            <button class="btn btn-primary mt-4 mr-4" id="land">LAND</button>
        </div>
        <div class="row d-flex justify-content-center">
                <button class="btn btn-light rounded-circle mt-4 mr-4" id="counterClockwise"> <span class="fas fa-undo"></span> </button>
                <button class="btn btn-light mt-4 mr-4" id="front"> <span class="fa fa-arrow-up"></span> </button>
                <button class="btn btn-light rounded-circle mt-4 mr-4" id="clockwise"> <span class="fas fa-redo"></span> </button>
        </div>
        <div class="row d-flex justify-content-center">
            <button class="btn btn-light mt-4 mr-4" id="left"><span class="fa fa-arrow-left"></span></button>
            <button class="btn btn-light mt-4 mr-4" id="back"><span class="fa fa-arrow-down"></span></button>
            <button class="btn btn-light mt-4 mr-4" id="right"><span class="fa fa-arrow-right"></span></button>
        </div>
        <div>
        <canvas width="500" height="500" style="border: black solid 1px;
          left:50px; top: 70px" id="myCanvas" >

        </canvas>
         <div id="placeholder" style="float: right; border:1px solid black;
         border-radius:10px;
         padding:10px; margin-top: 3em">
        </div>
        </div>
        <input type="file" id="image" onchange="app.loadPicture()"></br>

         <canvas width="500" height="500" style="border: black solid 1px;
          left:50px; top: 70px" id="hand" ></canvas> 

          <div class="wrapper">
    <div class="container">
      <canvas id="camera"></canvas>
      <canvas id="capturedImage"></canvas>
    </div>
    <div class="control">
      <div id="webCam" class="button play"><i class="fa fa-play fa-2x"></i></div>
      <div id="capture" class="button capture"><i class="fa fa-camera fa-2x"></i></div>
    </div>
    <label class="name">
      <input type="text" placeholder="Your name" autofocus="autofocus" />
    </label>
  </div>
    </div>
    <!-- <script src="https://cdn.jsdelivr.net/npm/handtrackjs/dist/handtrack.min.js"></script>  --> -->
    <script src="/nodecopter-client.js"></script>
    <script src="/face-api.min.js"></script>
     <script src="/socket.io/socket.io.js"></script>

    <script src="/Control/controlCanvas.js"></script>
    <script src="/Control/controlButton.js"></script>
    
    <script src="/LBP/Data.js"></script>
    <script src="/LBP/FaceMess.js"></script>
    <script src="/LBP/Histogram.js"></script>
    <script src="/LBP/ImageProcessor.js"></script>
    <script src="/LBP/Session.js"></script>
    <script src="/LBP/Utils.js"></script>
    <script src="/LBP/WebCam.js"></script>


    <script>
        function startArDRoneStream() {
            new NodecopterStream(document.getElementById("placeholder"), {port: 3001});
        }
        startArDRoneStream();
        //FaceApi y jsFeat para trabajar con el analisis de imagenes en tiempo real
        /*const video = document.getElementById("handtrack")
        const track = faceapi.createCanvasFromMedia(video)
        document.body.append(track)
        const displaySize = {width: video.width, height: video.height}
        faceapi.matchDimensions(track,displaySize)
        setInterval(async()=>{
            const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions()
            console.log(detections)
            const resizedDetections = faceapi.resizeResults(detections, displaySize)
            track.getContext('2d').clearRect(0, 0, canvas.width, canvas.height)
            faceapi.draw.drawDetections(canvas, resizedDetections)
            faceapi.draw.drawFaceLandmarks(canvas, resizedDetections)
            faceapi.draw.drawFaceExpressions(canvas, resizedDetections)
            }, 100)

            console.log('end')
*/
            //Le tengo que pasar un canvas de contexto 2D
//             handTtrack.load().then(async (model) => {
//         // detect objects in the image.
//     const droneVideo = document.getElementById('handtrack')
//     const predictions = await model.detect(droneVideo)
//     const data = await predictions.json()
//     console.log(data)
//     model.renderPredictions(predictions, document.getElementById('hand'),document.getElementById('hand').getContext('2d') , droneVideo)
//   });

    </script>
    <script src="/lbp.js"></script> <!--Adaptar adecuadamente el algoritmo para aplicarlo a mi drone-->

</body>
</html>